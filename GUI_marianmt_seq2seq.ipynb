{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2IqvirUjse5YVHWWMJ7dg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMAu6myNcdtu","executionInfo":{"status":"ok","timestamp":1748625646437,"user_tz":-420,"elapsed":25254,"user":{"displayName":"Tiến Thành Phùng","userId":"12605757166174286026"}},"outputId":"fd8215b9-dac5-4b56-d4d1-5f125a23cedd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/IT4772E - NLP/marianmt/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udDXjJhEcsRt","executionInfo":{"status":"ok","timestamp":1748625646850,"user_tz":-420,"elapsed":421,"user":{"displayName":"Tiến Thành Phùng","userId":"12605757166174286026"}},"outputId":"c6c51712-5965-4491-f67c-841eaac19f41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/IT4772E - NLP/marianmt\n"]}]},{"cell_type":"code","source":["pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2rkCAp7cziS","executionInfo":{"status":"ok","timestamp":1748625680882,"user_tz":-420,"elapsed":34030,"user":{"displayName":"Tiến Thành Phùng","userId":"12605757166174286026"}},"outputId":"58301818-054a-47c5-97da-3f86b3eae57b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.2 (from gradio)\n","  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.32.0-py3-none-any.whl (54.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.32.0 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","import torch\n","import torch.nn as nn\n","from transformers import MarianTokenizer, MarianMTModel, pipeline, AutoTokenizer\n","from tqdm import tqdm"],"metadata":{"id":"Na5jCfANc4O7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Định nghĩa lớp BahdanauAttention\n","class BahdanauAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(BahdanauAttention, self).__init__()\n","        self.Wa = nn.Linear(hidden_size * 2, hidden_size)\n","        self.Ua = nn.Linear(hidden_size * 2, hidden_size)\n","        self.Va = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)\n","        energy = torch.tanh(self.Wa(hidden) + self.Ua(encoder_outputs))\n","        scores = self.Va(energy).squeeze(-1)\n","        attn_weights = torch.softmax(scores, dim=1)\n","        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n","        return context, attn_weights\n","\n","# Định nghĩa lớp Encoder\n","class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","\n","    def forward(self, src):\n","        embedded = self.embedding(src)\n","        outputs, (hidden, cell) = self.lstm(embedded)\n","        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n","        cell = torch.cat((cell[-2], cell[-1]), dim=1)\n","        return outputs, hidden, cell\n","\n","# Định nghĩa lớp Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size + hidden_size * 2, hidden_size * 2, num_layers, batch_first=True)\n","        self.attention = BahdanauAttention(hidden_size)\n","        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n","\n","    def forward(self, tgt, hidden, cell, encoder_outputs):\n","        embedded = self.embedding(tgt)\n","        context, attn_weights = self.attention(hidden, encoder_outputs)\n","        lstm_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)\n","        output, (hidden, cell) = self.lstm(lstm_input, (hidden.unsqueeze(0), cell.unsqueeze(0)))\n","        output = self.fc(output.squeeze(1))\n","        return output, hidden.squeeze(0), cell.squeeze(0), attn_weights\n","\n","# Định nghĩa lớp Seq2Seq\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n","        batch_size = src.size(0)\n","        tgt_len = tgt.size(1)\n","        outputs = torch.zeros(batch_size, tgt_len, len(tokenizer)).to(device)\n","        encoder_outputs, hidden, cell = self.encoder(src)\n","        input = tgt[:, 0].unsqueeze(1)\n","        for t in range(1, tgt_len):\n","            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)\n","            outputs[:, t, :] = output\n","            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n","            top1 = output.argmax(1).unsqueeze(1)\n","            input = tgt[:, t].unsqueeze(1) if teacher_force else top1\n","        return outputs"],"metadata":{"id":"stqRt72sc6aC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm dịch với Beam Search cho Seq2Seq\n","def translate_sentence_seq2seq(model, src, tokenizer, beam_width=5, max_len=50, device='cuda'):\n","    model.eval()\n","    src = src.to(device)\n","    with torch.no_grad():\n","        encoder_outputs, hidden, cell = model.encoder(src)\n","        beams = [(torch.tensor([[tokenizer.cls_token_id]], dtype=torch.long).to(device), 0.0, hidden, cell)]\n","        completed = []\n","        for _ in range(max_len):\n","            new_beams = []\n","            for input, score, h, c in beams:\n","                if input[0, -1].item() == tokenizer.sep_token_id:\n","                    completed.append((input, score))\n","                    continue\n","                output, new_hidden, new_cell, _ = model.decoder(input[:, -1:], h, c, encoder_outputs)\n","                probs = torch.log_softmax(output, dim=-1).squeeze(1)\n","                top_probs, top_idx = probs.topk(beam_width, dim=-1)\n","                for i in range(beam_width):\n","                    new_input = torch.cat([input, top_idx[:, i:i+1]], dim=1)\n","                    new_score = score + top_probs[:, i].item()\n","                    new_beams.append((new_input, new_score, new_hidden, new_cell))\n","            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n","            if len(completed) >= beam_width:\n","                break\n","        if completed:\n","            best_sequence = max(completed, key=lambda x: x[1])[0]\n","        else:\n","            best_sequence = beams[0][0]\n","        return tokenizer.decode(best_sequence[0, 1:], skip_special_tokens=True)"],"metadata":{"id":"NP1c7_xYc-s6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm tải và dịch với MarianMT\n","def load_marianmt_model():\n","    model_path = \"./marian_finetuned_vi_final\"\n","    tokenizer = MarianTokenizer.from_pretrained(model_path)\n","    model = MarianMTModel.from_pretrained(model_path)\n","    return pipeline(\"translation\", model=model, tokenizer=tokenizer, device=0, max_length=256, num_beams=5, no_repeat_ngram_size=2)"],"metadata":{"id":"28ht5FKkdAGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm tải và dịch với Seq2Seq\n","def load_seq2seq_model(tokenizer):\n","    vocab_size = len(tokenizer)\n","    embed_size = 128\n","    hidden_size = 256\n","    num_layers = 1\n","    encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers)\n","    decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers)\n","    model = Seq2Seq(encoder, decoder).to(device)\n","    model.load_state_dict(torch.load(\"./best_model.pt\", map_location=device))\n","    return model"],"metadata":{"id":"WR78wubUdEhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm dịch tổng quát\n","def translate_text(input_text, model_choice):\n","    if not input_text.strip():\n","        return \"Vui lòng nhập văn bản!\"\n","\n","    try:\n","        if model_choice == \"MarianMT\":\n","            translator = load_marianmt_model()\n","            result = translator(input_text)[0][\"translation_text\"]\n","        else:  # Seq2Seq + Attention\n","            tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n","            model = load_seq2seq_model(tokenizer)\n","            tokens = tokenizer(input_text, max_length=50, padding='max_length', truncation=True, return_tensors='pt')\n","            result = translate_sentence_seq2seq(model, tokens['input_ids'], tokenizer, beam_width=5, max_len=50, device=device)\n","        return result\n","    except Exception as e:\n","        return f\"Lỗi: {str(e)}\""],"metadata":{"id":"FsF7iy7EdMFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Thiết lập thiết bị\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Tạo giao diện Gradio\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"# Ứng Dụng Dịch Anh - Việt\")\n","    input_box = gr.Textbox(label=\"Nhập câu tiếng Anh\", placeholder=\"Ví dụ: Hello world\")\n","    model_choice = gr.Dropdown(choices=[\"MarianMT\", \"Seq2Seq + Attention\"], label=\"Chọn mô hình dịch\")\n","    output_box = gr.Textbox(label=\"Kết quả tiếng Việt\")\n","    translate_button = gr.Button(\"Dịch\")\n","    translate_button.click(\n","        fn=translate_text,\n","        inputs=[input_box, model_choice],\n","        outputs=output_box\n","    )\n","\n","# Chạy ứng dụng\n","demo.launch(server_name=\"0.0.0.0\", server_port=7864)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"FHk4NPlZdOV7","executionInfo":{"status":"ok","timestamp":1748625768895,"user_tz":-420,"elapsed":2143,"user":{"displayName":"Tiến Thành Phùng","userId":"12605757166174286026"}},"outputId":"03c8c4c0-0605-45fe-ba0a-b6ceb013f509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://d81201667a978ecae5.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://d81201667a978ecae5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}]}]}